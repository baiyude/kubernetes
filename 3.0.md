# 第三版

### 模板脚本

```BASH
#!/bin/bash
#----------------------------------------------
# Author        : 349925756
# Email         : 349925756@qq.com
# Last modified : 2021-06-08 21:31
# Filename      : uuid.sh
# Description   : 
# Version       : 1.1 
#----------------------------------------------

#Notes:  
#!/bin/bash
#uuid  ip
path_eth0="/etc/sysconfig/network-scripts/ifcfg-eth0"
sed -i "/UUID/c UUID=$(uuidgen)" $path_eth0
sed -i "s/$1/$2/g" $path_eth0
echo "$3" >/etc/hostname
systemctl stop firewalld && systemctl disable firewalld
sed -i "s/SELINUX=.*/SELINUX=disabled/g" /etc/selinux/config
\cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
systemctl enable chronyd
yum install -y vim wget net-tools bash-completion tree nmap dos2unix lrzsz nc lsof tcpdump htop iftop iotop sysstat nethogs 
echo 'source /usr/share/bash-completion/bash_completion' >> ~/.bashrc
echo 'source <(kubectl completion bash)' >> ~/.bashrc
sed -ri 's/.*swap.*/#&/' /etc/fstab                                               
reboot

```

### 服务检查脚本

```BASH
[root@master01 ~]# cat service_check.sh
#!/bin/bash
#后面做个判断的
echo "Kube-apiserver_Check......"
#apiserver 检查
echo "+-------------------------------------------------------+";
for host in master01 master02 master03;do for i in kube-apiserver kube-controller-manager kube-scheduler;
do echo -e "    $host  $i is : \c" && ssh $host systemctl status $i|grep Active |awk -F"[()]" '{print $2}' ;done;done
echo "+-------------------------------------------------------+";
echo "Etcd_Check......"
echo "+-------------------------------------------------------+";

#etcd检查
for host in master01 master02 master03;do echo -e "    $host  etcd is  |  \c" && ssh $host systemctl status etcd|grep Active |awk -F"[()]" '{print $2}' ;done
echo "+-------------------------------------------------------+";

echo "docker_Check......"
echo "+-------------------------------------------------------+";
#docker检查
for host in master01 master02 master03 node01 node02;do echo -e "    $host  docker is  |  \c" && ssh $host systemctl status docker|grep Active |awk -F"[()]" '{print $2}' ;done
echo "+-------------------------------------------------------+";


echo "Kube-proxy kubelet_Check......"
#kubelet,proxy检查
echo "+-------------------------------------------------------+";
for host in master01 master02 master03 node01 node02;do for i in kube-proxy kubelet;
do echo -e "    $host  $i is : \c" && ssh $host systemctl status $i|grep Active |awk -F"[()]" '{print $2}' ;done;done
echo "+-------------------------------------------------------+";
```



## 一览表

![image-20210630213802774](C:\Users\goo\AppData\Roaming\Typora\typora-user-images\image-20210630213802774.png)



### 硬件

![image-20210630213621845](C:\Users\goo\AppData\Roaming\Typora\typora-user-images\image-20210630213621845.png)

### 软件

![image-20210630213643840](C:\Users\goo\AppData\Roaming\Typora\typora-user-images\image-20210630213643840.png)

### 组件下载

| **名称**           | **下载页面**                                                 |
| ------------------ | ------------------------------------------------------------ |
| **Centos**         | https://www.centos.org/download/                             |
| **Docker**         | https://download.docker.com/linux/static/stable/x86_64/      |
| **docker-compose** | https://github.com/docker/compose/releases/                  |
| **Kubernetes**     | https://github.com/kubernetes                                |
| **Calico**         | https://docs.projectcalico.org/getting-started/kubernetes/self-managed-onprem/onpremises |
| **Coredns**        | https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/dns/coredns |
| **Dashboard**      | https://github.com/kubernetes/dashboard/releases             |
| **cfssl**          | https://github.com/cloudflare/cfssl/releases                 |
| **Etcd**           | https://github.com/etcd-io/etcd/releases                     |

### 准备工作

**创建目录**

```bash
--存放软件的目录
[root@master01 ~]# mkdir -p /server/soft/

--存放tls证书目录，三套系统，避免一团糟
[root@master01 ~]# mkdir -p tls/{etcd,kubernetes,harbor}

--etcd工作目录 01 02 03
[root@master01 ~]# mkdir -p /opt/etcd/{cfg,logs,ssl}

--kubernetes工作目录
[root@master01 ~]# mkdir -p /opt/kubernetes/{cfg,logs,ssl}

--harbor服务目录只在主机节点使用
[root@master01 ~]# mkdir /opt/harbor

```

**设置主机名**

```BASH
[root@master01 ~]# echo -e "172.16.0.30 master01\n172.16.0.31 master02\n172.16.0.32 master03\n172.16.0.35 node01\n172.16.0.36 node02\n" >>/etc/hosts
[root@master01 ~]# hostname -i
172.16.0.30
[root@master01 ~]# hostname -s
master01
--其他主机信息一样的操作。我才用xshell 同时5台一起撰写
```

### 互信

```BASH
--xshell 撰写功能
[root@master01 ~]#  ssh-keygen -t rsa
[root@master01 ~]# ssh-copy-id master01
[root@master01 ~]# ssh-copy-id master02
[root@master01 ~]# ssh-copy-id master03
[root@master01 ~]# ssh-copy-id node01
[root@master01 ~]# ssh-copy-id node02
[root@master01 ~]# for i in `cat /root/host.txt`;do ssh $i hostname -s;done
master01
master02
master03
node01
node02
```

### 内核参数

```BASH
{ #all
[root@master01 ~]# cat > /etc/sysctl.d/k8s.conf << EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
[root@master01 ~]# sysctl --system
}
```

### 时间同步

集群最重要的功能

```BASH
{
[root@master01 ~]# yum install ntpdate -y 
[root@master01 ~]# systemctl start ntpdate && systemctl enable ntpdate 
[root@master01 ~]# echo 'ntpdate time.nist.gov' >>/etc/rc.local
[root@master01 ~]# chmod +x /etc/rc.d/rc.local
}
```



## cfssl

### cfssl 安装

```BASH
[root@master01 /server/soft]# chmod +x cfssl*
[root@master01 /server/soft]# ll
-rwxr-xr-x 1 root root  16377936 Jun 30 22:23 cfssl_1.6.0_linux_amd64
-rwxr-xr-x 1 root root  13245520 Jun 30 22:23 cfssl-certinfo_1.6.0_linux_amd64
-rwxr-xr-x 1 root root  10892112 Jun 30 22:23 cfssljson_1.6.0_linux_amd64
-rw-r--r-- 1 root root  69725147 Jun 30 22:24 docker-20.10.7.tgz
-rw-r--r-- 1 root root  19389988 Jun 30 22:23 etcd-v3.5.0-linux-amd64.tar.gz
-rw-r--r-- 1 root root 342258563 Jun 30 22:25 kubernetes-server-linux-amd64_1.21.2.tar.gz
[root@master01 /server/soft]# mv cfssl-certinfo_1.6.0_linux_amd64 /usr/local/bin/cfssl-certinfo
[root@master01 /server/soft]# mv cfssl_1.6.0_linux_amd64 /usr/local/bin/cfssl
[root@master01 /server/soft]# mv cfssljson_1.6.0_linux_amd64 /usr/local/bin/cfssljson
```

自签名证书

https://github.com/coreos/docs/blob/master/os/generate-self-signed-certificates.md

```BASH
#初始化证书颁发机构
mkdir ~/cfssl
cd ~/cfssl
cfssl print-defaults config > ca-config.json
cfssl print-defaults csr > ca-csr.json

ca-config.json默认
profile:www with server auth(TLS服务端验证)  x509 v3 client auth（客户端验证）
expiry:默认8760h 默认是一年
样本：ca-config.json
{
    "signing": {
        "default": {
            "expiry": "87600h"
        },
        "profiles": {
            "server": {
                "expiry": "87600h",
                "usages": [
                    "signing",
                    "key encipherment",
                    "server auth"
                ]
            },
            "client": {
                "expiry": "87600h",
                "usages": [
                    "signing",
                    "key encipherment",
                    "client auth"
                ]
            },
            "peer": {
                "expiry": "87600h",
                "usages": [
                    "signing",
                    "key encipherment",
                    "server auth",
                    "client auth"
                ]
            }
        }
    }
}

样本：ca-csr.json
{
    "CN": "My own CA",
    "key": {
        "algo": "rsa",
        "size": 2048
    },
    "names": [
        {
            "C": "US",
            "L": "CA",
            "O": "My Company Name",
            "ST": "San Francisco",
            "OU": "Org Unit 1",
            "OU": "Org Unit 2"
        }
    ]
}

#生成证书和密钥
cfssl gencert -initca ca-csr.json | cfssljson -bare ca -

ca-key.pem   #密钥，此证书允许在CA中创建任何类型的证书
ca.csr
ca.pem

生成服务器证书
cfssl print-defaults csr > server.json
```

服务器证书最重要的是CN和host必须修改

```BASH
...
    "CN": "coreos1",
    "hosts": [
        "192.168.122.68",
        "ext.example.com",
        "coreos1.local",
        "coreos1"
    ],
...

生成服务器证书和密钥
cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server server.json | cfssljson -bare server

没有上面的json文件可以使用下面的替代
echo '{"CN":"coreos1","hosts":[""],"key":{"algo":"rsa","size":2048}}' | cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server -hostname="192.168.122.68,ext.example.com,coreos1.local,coreos1" - | cfssljson -bare server
一般建议留文件方便后期查阅

```

生成对等证书

```BASH
cfssl print-defaults csr > member1.json

...
    "CN": "member1",
    "hosts": [
        "192.168.122.101",
        "ext.example.com",
        "member1.local",
        "member1"
    ],
...

cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=peer member1.json | cfssljson -bare member1

或者：
echo '{"CN":"member1","hosts":[""],"key":{"algo":"rsa","size":2048}}' | cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=peer -hostname="192.168.122.101,ext.example.com,member1.local,member1" - | cfssljson -bare member1
对每个etcd成员主机名重复这些步骤。


```

生成客户端连接证书

```BASH
cfssl print-defaults csr > client.json
对于客户端证书，我们可以忽略主机值并仅将通用名称 (CN) 设置为客户端值：
...
    "CN": "client",
    "hosts": [""],
...

cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=client client.json | cfssljson -bare client

或者
echo '{"CN":"client","hosts":[""],"key":{"algo":"rsa","size":2048}}' | cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=client - | cfssljson -bare client

验证数据
openssl x509 -in ca.pem -text -noout 
openssl x509 -in server.pem -text -noout 
openssl x509 -in client.pem -text -noout
不要把你的ca-key.pem放到 Container Linux Config 中，建议存放在安全的地方。此密钥允许生成尽可能多的证书。
妥善保管关键文件。不要忘记设置适当的文件权限，即chmod 0600 server-key.pem.
此TLDR示例中的证书具有server auth和client authX509 V3 扩展，您可以将它们用于服务器和客户端的身份验证。
您也可以自由地为通配符*地址生成密钥和证书。他们将在任何机器上工作。它将简化证书程序，但会增加安全风险。
```



### Etcd证书

http://play.etcd.io/install

```BASH
[root@master01 ~]# cd tls/etcd/
---------------------------------------------------------------------------------
cat > ca-csr.json <<EOF
{
    "CN": "etcd",
    "hosts": [],
    "key": {
        "algo": "rsa",
        "size": 2048
    },
    "names": [
        {
            "C": "CN",
            "ST": "Yunnan",
            "L": "Kunming",
            "O": "etcd",
            "OU": "ops"
        }                                                                                                                    
    ]
}
EOF

#ca.csr  ca-csr.json  ca-key.pem  ca.pem
--------------------------------------------------------------------------------
cfssl gencert -initca ca-csr.json | cfssljson -bare ca -
--------------------------------------------------------------------------------
# verify 核实
openssl x509 -in ca.pem -text -noout
--------------------------------------------------------------
# cert-generation configuration  证书生成配置
cat > ca-config.json << EOF
{
    "signing": {
        "default": {
            "expiry": "87600h"
        },
        "profiles": {
            "server": {
                "expiry": "87600h",
                "usages": [
                    "signing",
                    "key encipherment",
                    "server auth"
                ]
            },
            "client": {
                "expiry": "87600h",
                "usages": [
                    "signing",
                    "key encipherment",
                    "client auth"
                ]
            },
            "peer": {
                "expiry": "87600h",
                "usages": [
                    "signing",
                    "key encipherment",
                    "server auth",
                    "client auth"
                ]
            }
        }
    }
}
EOF

-------------------------------------------------------------
# CSR 配置
ca-csr.json 

#企业社会责任
ca.csr

# 自签名根 CA 公钥
ca.pem

# 自签名根 CA 私钥
ca-key.pem

# 其他 TLS 资产的证书生成配置
ca-config.json

--------------------------------
#使用本地私钥颁布证书供远程主机访问，这里有3台服务器就生成三台

cat > server-csr.json <<EOF
{
    "CN": "etcd",
    "hosts": [
        "172.16.0.30",
        "172.16.0.31",
        "172.16.0.32",
        "172.16.0.33",
        "172.16.0.34"
    ],
    "key": {
        "algo": "rsa",
        "size": 2048
    },
    "names": [
        {
            "C": "CN",
            "ST": "Yunnan",
            "L": "Kunming",
            "O": "etcd",
            "OU": "ops"
        }
    ]
}
EOF

#server.csr  server-csr.json  server-key.pem  server.pem
------------------------------------
cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server server-csr.json | cfssljson -bare server
------------------------------------
# verify
openssl x509 -in server.pem -text -noout

#上面ca-config.json 被分成server,client,peer  其中server ,peer配置相同，client 配置CN就是客户端host忽略，空即可。etcd中只用到peer，但是apiserver就是etcd的客户端。所以这里要生成。

cat > client-csr.json <<EOF
{
    "CN": "client",
    "hosts": [],
    "key": {
        "algo": "rsa",
        "size": 2048
    },
    "names": [
        {
            "C": "CN",
            "ST": "Yunnan",
            "L": "Kunming",
            "O": "etcd",
            "OU": "ops"
        }
    ]
}
EOF
#client.csr  client-csr.json  client-key.pem  client.pem

cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=client client-csr.json | cfssljson -bare client

openssl x509 -in client.pem -text -noout
```

```BASH
--------------------------------------
通过人工方式校验
--------------------------------------
basicConstraints CA:FALSE基本约束，实际是为了标志当前签发的证书是否为CA证书，CA:FALSE表明为非CA证书，这种证书无法用来签发其他证书
也就是说这个证书是最终证书了

确认 Issuer 字段的内容和 ca-csr.json 一致；
确认 Subject 字段的内容和 kubernetes-csr.json 一致；
确认 X509v3 Subject Alternative Name 字段的内容和 kubernetes-csr.json 一致；
确认 X509v3 Key Usage、Extended Key Usage 字段的内容和 ca-config.json 中 kubernetesprofile 一致；
# cfssl-certinfo -cert kubernetes.pem
--------------------------------------
通过对比方式校验
--------------------------------------
[root@master01 ~/tls/etcd]# openssl verify -CAfile ca.pem server.pem
server.pem: OK
[root@master01 ~/tls/etcd]# openssl verify -CAfile ca.pem client.pem
client.pem: OK

校验证书是否被CA签名
https://github.com/kubernetes-sigs/apiserver-builder-alpha/blob/master/docs/concepts/auth.md
```

把生成的证书分发到对应的目录

```BASH
#etcd 本身使用的凭证和密钥
[root@master01 ~/tls/etcd]# cp ca.pem server.pem server-key.pem /opt/etcd/ssl/  
#apiserver使用的凭证和密钥
[root@master01 ~/tls/etcd]# cp client.pem client-key.pem /opt/etcd/ssl/
[root@master01 ~/tls/etcd]# cp peer*.pem /opt/etcd/ssl/

```

下载并安装etcd

```BASH
[root@master01 /server/soft]# tar xf etcd-v3.5.0-linux-amd64.tar.gz 
[root@master01 /server/soft]# mv etcd-v3.5.0-linux-amd64/etcd* /usr/local/bin/
[root@master01 /server/soft]# etcd --version
etcd Version: 3.5.0
Git SHA: 946a5a6f2
Go Version: go1.16.3
Go OS/Arch: linux/amd64
```

配置文件

```BASH
[root@master01 /server/soft]#  for i in master01 master02 master03;do scp /usr/local/bin/etcd* $i:/usr/local/bin/;done
[root@master01 /server/soft]# for i in master01 master02 master03;do scp -r  /opt/etcd $i:/opt/;done
--------------------------------------------------------------------
ETCD_IP=$(hostname -i)
ETCD_NAME=$(hostname -s)
ETCD_PATH="/opt/etcd/ssl/"

cat > /etc/systemd/system/etcd.service <<EOF
[Unit]
Description=ETCD Server
Documentation=https://github.com/coreos/etcd
After=network.target
After=network-online.target
Wants=network-online.target

[Service]
Type=notify
ExecStart=/usr/local/bin/etcd --name ${ETCD_NAME} \\
  --cert-file ${ETCD_PATH}peer.pem \\
  --key-file ${ETCD_PATH}peer-key.pem \\
  --peer-cert-file ${ETCD_PATH}peer.pem \\
  --peer-key-file ${ETCD_PATH}peer-key.pem \\
  --trusted-ca-file ${ETCD_PATH}ca.pem \\
  --peer-trusted-ca-file ${ETCD_PATH}ca.pem \\
  --peer-client-cert-auth \\
  --client-cert-auth \\
  --listen-client-urls https://${ETCD_IP}:2379 \\
  --advertise-client-urls https://${ETCD_IP}:2379 \\
  --listen-peer-urls https://${ETCD_IP}:2380 \\
  --initial-advertise-peer-urls https://${ETCD_IP}:2380 \\
  --initial-cluster master01=https://172.16.0.30:2380,master02=https://172.16.0.31:2380,master03=https://172.16.0.32:2380 \\
  --initial-cluster-token etcd_cluster \\
  --initial-cluster-state new \\
  --data-dir=/var/lib/etcd/default.etcd 
Restart=on-failure

[Install]
WantedBy=multi-user.target
EOF
----------------------------------------------------------------
  ETCDCTL_API=3 etcdctl \
  --endpoints https://172.16.0.30:2379,https://172.16.0.31:2379,https://172.16.0.32:2379 \
  --cacert /opt/etcd/ssl/ca.pem \
  --cert /opt/etcd/ssl/peer.pem \
  --key /opt/etcd/ssl/peer-key.pem \
  endpoint health \
  --write-out=table
 --------------------------------------------------------------
 +--------------------------+--------+-------------+-------+
|         ENDPOINT         | HEALTH |    TOOK     | ERROR |
+--------------------------+--------+-------------+-------+
| https://172.16.0.30:2379 |   true |  9.652858ms |       |
| https://172.16.0.31:2379 |   true |  9.723983ms |       |
| https://172.16.0.32:2379 |   true | 13.150944ms |       |
+--------------------------+--------+-------------+-------+

  
# to start service
systemctl daemon-reload && systemctl start etcd && systemctl enable etcd
[root@master01 ~]# for host in master01 master02 master03 ;do ssh $host systemctl status etcd | grep Active ;done


# to get logs from service
systemctl status etcd.service -l --no-pager
journalctl -u etcd -l --no-pager|less
journalctl -f -u etcd

# to stop service
sudo systemctl stop s1.service
sudo systemctl disable s1.service
```



#### etcd配置文件说明

```BASH
#客户端到服务器端的通信
--cert-file=<path>：用于与etcd 的SSL/TLS 连接的证书。设置此选项后，advertise-client-urls 可以    使用 HTTPS 架构
--key-file=<path>: 证书密钥。必须是未加密的
--client-cert-auth: 设置此选项后，etcd 将检查所有传入的 HTTPS 请求以获取由受信任的 CA 签署的客    户端证书，不提供有效客户端证书的请求将失败。如果启用了身份验证，则证书会为 Common Name          字段提供的用户名提供凭据
--trusted-ca-file=<path>: 受信任的证书颁发机构
--auto-tls：使用自动生成的自签名证书与客户端进行 TLS 连接
#对等通信（服务器到服务器，集群）
--peer-cert-file=<path>：用于对等方之间的 SSL/TLS 连接的证书。这将用于侦听对等地址以及向其他对    等方发送请求
--peer-key-file=<path>: 证书密钥。必须是未加密的
--peer-client-cert-auth：设置后，etcd 将检查来自集群的所有传入对等请求，以获取由提供的 CA 签署    的有效客户端证书
--peer-trusted-ca-file=<path>: 受信任的证书颁发机构
--peer-auto-tls：使用自动生成的自签名证书进行对等方之间的 TLS 连接

如果提供了客户端到服务器或对等证书，则还必须设置密钥。所有这些配置选项也可通过环境变量ETCD_CA_FILE，ETCD_PEER_CA_FILE等等。
--cipher-suites：服务器/客户端和对等点之间支持的 TLS 密码套件的逗号分隔列表（空将由 Go 自动填充）。可用于 v3.2.22+、v3.3.7+ 和 v3.4+。
```

验证

```BASH
#启动
$ etcd --name infra0 --data-dir infra0 \
  --cert-file=/path/to/server.crt --key-file=/path/to/server.key \
  --advertise-client-urls=https://127.0.0.1:2379 --listen-client-urls=https://127.0.0.1:2379
----------------------------------------
[root@master01 ~]# curl --cacert /opt/etcd/server.pem https://172.16.0.30:2379/v2/keys/foo -XPUT -d value=bar -v
* About to connect() to 172.16.0.30 port 2379 (#0)
*   Trying 172.16.0.30...
* Connected to 172.16.0.30 (172.16.0.30) port 2379 (#0)
* Initializing NSS with certpath: sql:/etc/pki/nssdb
* Closing connection 0

$ curl --cacert /path/to/ca.crt --cert /path/to/client.crt --key /path/to/client.key \
  -L https://127.0.0.1:2379/v2/keys/foo -XPUT -d value=bar -v
  
  https://etcd.io/docs/v3.5/op-guide/security/
```

## Docker

docker安装

```BASH
[root@master01 /server/soft]# chmod +x docker-compose-Linux-x86_64 
[root@master01 /server/soft]# mv docker-compose-Linux-x86_64 /usr/local/bin/docker-compose
[root@master01 /server/soft]# for i in `cat /root/host.txt`;do scp /usr/local/bin/docker-compose $i:/usr/local/bin/;done
[root@master01 /server/soft]# docker-compose --version
docker-compose version 1.29.2, build 5becea4c
[root@master01 /server/soft]# for i in `cat /root/host.txt`;do scp docker/* $i:/usr/bin/;done
[root@master01 /server/soft]# docker --version
Docker version 20.10.7, build f0df350
[root@master01 /server/soft]# cat > /etc/systemd/system/docker.service << EOF
[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network-online.target firewalld.service
Wants=network-online.target
[Service]
Type=notify
ExecStart=/usr/bin/dockerd
ExecReload=/bin/kill -s HUP $MAINPID
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity
TimeoutStartSec=0
Delegate=yes
KillMode=process
Restart=on-failure
StartLimitBurst=3
StartLimitInterval=60s
[Install]
WantedBy=multi-user.target
EOF

[root@master01 /server/soft]# for i in `cat /root/host.txt`;do scp /etc/systemd/system/docker.service $i:/etc/systemd/system/;done

[root@master01 /server/soft]# for i in `cat /root/host.txt`;do
  ssh $i systemctl daemon-reload && systemctl start docker && systemctl enable docker && systemctl status docker |grep Active;echo -e "--------$i--------";done
  
```

## kubernetes

准备工作

```BASH
[root@master01 /server/soft]# tar xf kubernetes-server-linux-amd64_1.21.2.tar.gz 
--服务端命令
[root@master01 /server/soft/kubernetes/server/bin]# for i in master01 master02 master03;do scp kube-apiserver kube-scheduler kube-controller-manager $i:/usr/local/bin;done

--客户端命令
[root@master01 /server/soft/kubernetes/server/bin]# for i in `cat /root/host.txt`;do scp kubectl kubelet kube-proxy kubeadm $i:/usr/local/bin;done

```



### apiserver

```BASH
cat > ca-csr.json <<EOF
{
    "CN": "kubernetes",
    "hosts": [],
    "key": {
        "algo": "rsa",
        "size": 2048
    },
    "names": [
        {
            "C": "CN",
            "ST": "Yunnan",
            "L": "Kunming",
            "O": "kubernetes",
            "OU": "System"
        }                                                                                                                    
    ]
}
EOF

#ca.csr  ca-csr.json  ca-key.pem  ca.pem
--------------------------------------------------------------------------------
cfssl gencert -initca ca-csr.json | cfssljson -bare ca -
--------------
openssl x509 -in ca.pem -text -noout

cat > ca-config.json << EOF
{
    "signing": {
        "default": {
            "expiry": "87600h"
        },
        "profiles": {
            "kubernetes": {
                "expiry": "87600h",
                "usages": [
                    "signing",
                    "key encipherment",
                    "server auth",
                    "client auth"
                ]
            }
        }
    }
}
EOF
--------------------------------------
cat > kube-apiserver-csr.json << EOF
{
    "CN": "kubernetes",
    "hosts": [
      "10.0.0.1",
      "127.0.0.1",
      "172.16.0.30",
      "172.16.0.31",
      "172.16.0.32",
      "172.16.0.33",
      "172.16.0.34",
      "172.16.0.35",
      "172.16.0.36",
      "kubernetes",
      "kubernetes.default",
      "kubernetes.default.svc",
      "kubernetes.default.svc.cluster",
      "kubernetes.default.svc.cluster.local"
    ],
    "key": {
        "algo": "rsa",
        "size": 2048
    },
    "names": [
        {
            "C": "CN",
            "L": "Kunming",
            "ST": "Yunnan",
            "O": "kubernetes",
            "OU": "System"
        }
    ]
}
EOF
--------------------
[root@master01 ~/tls/kubernetes]# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-apiserver-csr.json | cfssljson -bare kube-apiserver
--------------------
[root@master01 ~/tls/kubernetes]# openssl verify -CAfile ca.pem kube-apiserver.pem
kube-apiserver.pem: OK

```

配置

```BASH
[root@master01 ~/tls/kubernetes]# kube-apiserver --version
Kubernetes v1.21.2
[root@master01 ~/tls/kubernetes]# cp ca.pem kube-apiserver.pem kube-apiserver-key.pem /opt/kubernetes/ssl/
[root@master01 ~/tls/kubernetes]# tree /opt/kubernetes/
/opt/kubernetes/
├── cfg
├── logs
└── ssl
    ├── ca.pem
    ├── kube-apiserver-key.pem
    └── kube-apiserver.pem
-------------------------------------------    
生成token.csv
[root@master01 ~/tls/kubernetes]# head -c 16 /dev/urandom | od -An -t x | tr -d ' '
be0ab9901b4d2b9a89a39b6d37e58d25

[root@master01 ~/tls/kubernetes]# cat > /opt/kubernetes/cfg/token.csv << EOF
be0ab9901b4d2b9a89a39b6d37e58d25,kubelet-bootstrap,10001,"system:node-bootstrapper"
EOF
# 格式：token，用户名，UID，用户组


#获取IP地址
INTERNAL_IP=$(hostname -i)
#生成kube-apiserver.service systemd文件
cat >/etc/systemd/system/kube-apiserver.service<<EOF 
[Unit]
Description=Kubernetes API Server
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-apiserver \\
--logtostderr=false \\
--v=2 \\
--log-dir=/opt/kubernetes/logs \\
--etcd-servers=https://172.16.0.30:2379,https://172.16.0.31:2379,https://172.16.0.32:2379 \\
--bind-address=${INTERNAL_IP}  \\  
--secure-port=6443 \\
--advertise-address=${INTERNAL_IP}  \\
--allow-privileged=true \\
--apiserver-count=3 \\
--service-cluster-ip-range=10.0.0.0/24 \\
--enable-admission-plugins=NamespaceLifecycle,NodeRestriction,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota \\
--authorization-mode=Node,RBAC \\
--enable-bootstrap-token-auth=true \\
--token-auth-file=/opt/kubernetes/cfg/token.csv \\
--service-node-port-range=30000-32767 \\
--kubelet-certificate-authority=/opt/kubernetes/ssl/ca.pem \\
--kubelet-client-certificate=/opt/kubernetes/ssl/kube-apiserver.pem \\
--kubelet-client-key=/opt/kubernetes/ssl/kube-apiserver-key.pem \\
--tls-cert-file=/opt/kubernetes/ssl/kube-apiserver.pem \\
--tls-private-key-file=/opt/kubernetes/ssl/kube-apiserver-key.pem \\
--client-ca-file=/opt/kubernetes/ssl/ca.pem \\
--service-account-issuer=api \\
--service-account-key-file=/opt/kubernetes/ssl/ca-key.pem \\
--service-account-signing-key-file=/opt/kubernetes/ssl/kube-apiserver-key.pem \\ 
--etcd-cafile=/opt/etcd/ssl/ca.pem \\
--etcd-certfile=/opt/etcd/ssl/client.pem \\
--etcd-keyfile=/opt/etcd/ssl/client-key.pem \\
--requestheader-client-ca-file=/opt/kubernetes/ssl/ca.pem \\
--proxy-client-cert-file=/opt/kubernetes/ssl/kube-apiserver.pem \\
--proxy-client-key-file=/opt/kubernetes/ssl/kube-apiserver-key.pem \\
--requestheader-allowed-names=kubernetes \\
--requestheader-extra-headers-prefix=X-Remote-Extra- \\
--requestheader-group-headers=X-Remote-Group \\
--requestheader-username-headers=X-Remote-User \\
--enable-aggregator-routing=true \\

--audit-log-maxage=30 \\
--audit-log-maxbackup=3 \\
--audit-log-maxsize=100 \\
--audit-log-path=/opt/kubernetes/logs/k8s-audit.log 
Restart=on-failure

[Install]
WantedBy=multi-user.target

EOF
---------------------------------------------------------
参数说明：
https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-apiserver/
------------------------------------------------------------------------------------

systemctl daemon-reload && systemctl start kube-apiserver && systemctl enable kube-apiserver
```

### kube-controller-manager

证书

```BASH
cat > kube-controller-manager-csr.json <<EOF
{
  "CN": "system:kube-controller-manager",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "L": "Kunming",
      "O": "system:kube-controller-manager",
      "OU": "System",
      "ST": "Yunnan"
    }
  ]
}
EOF

[root@master01 ~/tls/kubernetes]# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-controller-manager-csr.json | cfssljson -bare kube-controller-manager
--------------------
[root@master01 ~/tls/kubernetes]# openssl verify -CAfile ca.pem kube-controller-manager.pem
kube-controller-manager.pem: OK
```

配置

```BASH
KUBE_CONFIG="/opt/kubernetes/cfg/kube-controller-manager.kubeconfig"
KUBE_APISERVER="https://172.16.0.30:6443"

kubectl config set-cluster kubernetes \
  --certificate-authority=/opt/kubernetes/ssl/ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=${KUBE_CONFIG}
  
kubectl config set-credentials kube-controller-manager \
  --client-certificate=./kube-controller-manager.pem \
  --client-key=./kube-controller-manager-key.pem \
  --embed-certs=true \
  --kubeconfig=${KUBE_CONFIG}
  
kubectl config set-context default \
  --cluster=kubernetes \
  --user=kube-controller-manager \
  --kubeconfig=${KUBE_CONFIG}
  
kubectl config use-context default --kubeconfig=${KUBE_CONFIG}

------------------------------------------------------------------------
cat <<EOF | tee /etc/systemd/system/kube-controller-manager.service
[Unit]
Description=Kubernetes Controller Manager
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-controller-manager --logtostderr=false \\
--v=2 \\
--log-dir=/opt/kubernetes/logs \\
--leader-elect=true \\
--kubeconfig=/opt/kubernetes/cfg/kube-controller-manager.kubeconfig \\
--bind-address=127.0.0.1 \\
--allocate-node-cidrs=true \\
--cluster-cidr=10.244.0.0/16 \\
--service-cluster-ip-range=10.0.0.0/24 \\
--cluster-signing-cert-file=/opt/kubernetes/ssl/ca.pem \\
--cluster-signing-key-file=/opt/kubernetes/ssl/ca-key.pem  \\
--root-ca-file=/opt/kubernetes/ssl/ca.pem \\
--service-account-private-key-file=/opt/kubernetes/ssl/ca-key.pem \\
--cluster-signing-duration=87600h0m0s
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
EOF

[root@master01 ~/tls/kubernetes]# for i in master{01..03};do scp /etc/systemd/system/kube-controller-manager.service $i:/etc/systemd/system/;done
kube-controller-manager.service                     100%  887     2.0MB/s   00:00    
kube-controller-manager.service                     100%  887   864.5KB/s   00:00    
kube-controller-manager.service                     100%  887   967.4KB/s   00:00    
[root@master01 ~/tls/kubernetes]# for i in master{01..03};do scp /opt/kubernetes/cfg/kube-controller-manager.kubeconfig $i:/opt/kubernetes/cfg/;done
kube-controller-manager.kubeconfig                  100% 6329     7.7MB/s   00:00    
kube-controller-manager.kubeconfig                  100% 6329     4.2MB/s   00:00    
kube-controller-manager.kubeconfig                  100% 6329     3.7MB/s   00:00    

systemctl daemon-reload && systemctl start kube-controller-manager && systemctl enable kube-controller-manager


```

### kube-scheduler

```BASH
cat > kube-scheduler-csr.json << EOF
{
  "CN": "system:kube-scheduler",
  "hosts": [],
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "L": "Kunming",
      "ST": "Yunnan",
      "O": "system:masters",
      "OU": "System"
    }
  ]
}
EOF

[root@master01 ~/tls/kubernetes]# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-scheduler-csr.json | cfssljson -bare kube-scheduler
--------------------
[root@master01 ~/tls/kubernetes]# openssl verify -CAfile ca.pem kube-scheduler.pem
kube-scheduler.pem: OK
```

配置

```BASH
KUBE_CONFIG="/opt/kubernetes/cfg/kube-scheduler.kubeconfig"
KUBE_APISERVER="https://172.16.0.30:6443"

kubectl config set-cluster kubernetes \
  --certificate-authority=/opt/kubernetes/ssl/ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=${KUBE_CONFIG}
  
kubectl config set-credentials kube-scheduler \
  --client-certificate=./kube-scheduler.pem \
  --client-key=./kube-scheduler-key.pem \
  --embed-certs=true \
  --kubeconfig=${KUBE_CONFIG}
  
kubectl config set-context default \
  --cluster=kubernetes \
  --user=kube-scheduler \
  --kubeconfig=${KUBE_CONFIG}
  
kubectl config use-context default --kubeconfig=${KUBE_CONFIG}

-------------------------------------------------------------------
cat > /etc/systemd/system/kube-scheduler.service << EOF
[Unit]
Description=Kubernetes Scheduler
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-scheduler --logtostderr=false \\
--v=2 \\
--log-dir=/opt/kubernetes/logs \\
--leader-elect=true \\
--kubeconfig=/opt/kubernetes/cfg/kube-scheduler.kubeconfig \\
--bind-address=127.0.0.1

Restart=on-failure

[Install]
WantedBy=multi-user.target
EOF
-------------------------------------------
systemctl daemon-reload && systemctl start kube-scheduler && systemctl enable kube-scheduler

```

### 生成kubectl链接集群的证书

```BASH
cat > admin-csr.json <<EOF
{
  "CN": "admin",
  "hosts": [],
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "L": "Kunming",
      "ST": "Yunnan",
      "O": "system:masters",
      "OU": "System"
    }
  ]
}
EOF

[root@master01 ~/tls/kubernetes]# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes admin-csr.json | cfssljson -bare admin
--------------------
[root@master01 ~/tls/kubernetes]# openssl verify -CAfile ca.pem admin.pem
admin.pem: OK

```

生成配置

```BASH
[root@master01 ~/tls/kubernetes]# mkdir /root/.kube

---------------------------------------------------
KUBE_CONFIG="/root/.kube/config"
KUBE_APISERVER="https://172.16.0.30:6443"

kubectl config set-cluster kubernetes \
  --certificate-authority=./ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=${KUBE_CONFIG}
  
kubectl config set-credentials cluster-admin \
  --client-certificate=./admin.pem \
  --client-key=./admin-key.pem \
  --embed-certs=true \
  --kubeconfig=${KUBE_CONFIG}
  
kubectl config set-context default \
  --cluster=kubernetes \
  --user=cluster-admin \
  --kubeconfig=${KUBE_CONFIG}
  
kubectl config use-context default --kubeconfig=${KUBE_CONFIG}

[root@master01 ~/tls/kubernetes]# kubectl get cs
Warning: v1 ComponentStatus is deprecated in v1.19+
NAME                 STATUS    MESSAGE                         ERROR
scheduler            Healthy   ok                              
controller-manager   Healthy   ok                              
etcd-2               Healthy   {"health":"true","reason":""}   
etcd-1               Healthy   {"health":"true","reason":""}   
etcd-0               Healthy   {"health":"true","reason":""}   

--授权kubelet-bootstrap用户允许请求证书
kubectl create clusterrolebinding kubelet-bootstrap \
--clusterrole=system:node-bootstrapper \
--user=kubelet-bootstrap

```

## node

### kubelet

```BASH
[root@node01 ~]# mkdir -p /opt/kubernetes/{cfg,logs,ssl}
[root@node02 ~]# mkdir -p /opt/kubernetes/{cfg,logs,ssl}

```

配置

```BASH

--------------------------------------------------------------
cat > /opt/kubernetes/cfg/kubelet-config.yml << EOF
kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
address: 0.0.0.0
port: 10250
readOnlyPort: 10255
cgroupDriver: cgroupfs
clusterDNS:
- 10.0.0.2
clusterDomain: cluster.local 
failSwapOn: false
authentication:
  anonymous:
    enabled: false
  webhook:
    cacheTTL: 2m0s
    enabled: true
  x509:
    clientCAFile: /opt/kubernetes/ssl/ca.pem 
authorization:
  mode: Webhook
  webhook:
    cacheAuthorizedTTL: 5m0s
    cacheUnauthorizedTTL: 30s
evictionHard:
  imagefs.available: 15%
  memory.available: 100Mi
  nodefs.available: 10%
  nodefs.inodesFree: 5%
maxOpenFiles: 1000000
maxPods: 110
EOF

--------------------------------------------------------------
KUBE_CONFIG="/opt/kubernetes/cfg/bootstrap.kubeconfig"
KUBE_APISERVER="https://172.16.0.30:6443"
TOKEN="be0ab9901b4d2b9a89a39b6d37e58d25"
# 与token.csv里保持一致

# 生成 kubelet bootstrap kubeconfig 配置文件
kubectl config set-cluster kubernetes \
  --certificate-authority=/opt/kubernetes/ssl/ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=${KUBE_CONFIG}
  
kubectl config set-credentials "kubelet-bootstrap" \
  --token=${TOKEN} \
  --kubeconfig=${KUBE_CONFIG}
  
kubectl config set-context default \
  --cluster=kubernetes \
  --user="kubelet-bootstrap" \
  --kubeconfig=${KUBE_CONFIG}
  
kubectl config use-context default --kubeconfig=${KUBE_CONFIG}
---------------------------------------------------------------------
KUBELET_NAME=$(hostname -s)

cat > /etc/systemd/system/kubelet.service << EOF
[Unit]
Description=Kubernetes Kubelet
After=docker.service

[Service]
EnvironmentFile=/opt/kubernetes/cfg/kubelet.conf
ExecStart=/usr/local/bin/kubelet --logtostderr=false \\
--v=2 \\
--log-dir=/opt/kubernetes/logs \\
--hostname-override=${KUBELET_NAME} \\
--network-plugin=cni \\
--kubeconfig=/opt/kubernetes/cfg/kubelet.kubeconfig \\
--bootstrap-kubeconfig=/opt/kubernetes/cfg/bootstrap.kubeconfig \\
--config=/opt/kubernetes/cfg/kubelet-config.yml \\
--cert-dir=/opt/kubernetes/ssl \\
--pod-infra-container-image=lizhenliang/pause-amd64:3.0
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
EOF

systemctl daemon-reload && systemctl start kubelet && systemctl enable kubelet
```

### kube-proxy
